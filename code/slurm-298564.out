Sun Mar  5 13:26:39 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |
| 30%   32C    P8    29W / 350W |      1MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Jun__8_16:49:14_PDT_2022
Cuda compilation tools, release 11.7, V11.7.99
Build cuda_11.7.r11.7/compiler.31442593_0
03/05/2023 13:26:58 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='Salesforce/codet5-base', dev_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/val-Python-desc-tok.py,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/val-Python-desc-tok.txt', do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_batch_size=16, eval_steps=2500, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=-1, max_grad_norm=1.0, max_source_length=400, max_steps=-1, max_target_length=100, model_name_or_path='Salesforce/codet5-base', model_type='codet5', no_cuda=False, num_train_epochs=10.0, output_dir='/home/ysnamgoong42/ws/XLCoST/codet5_pl_nl_program/Python-desc', seed=42, test_filename=None, tokenizer_name='Salesforce/codet5-base', train_batch_size=16, train_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/train-Python-desc-tok.py,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/train-Python-desc-tok.txt', train_steps=5000, warmup_steps=0, weight_decay=0.0)
03/05/2023 13:26:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/05/2023 13:27:14 - INFO - __main__ -   *** Example ***
03/05/2023 13:27:14 - INFO - __main__ -   idx: 0
03/05/2023 13:27:14 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_max', 'Pres', 'um', '_(', '_a', '_,', '_b', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_X', '_=', '_max', '_(', '_a', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_a', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_a', '_[', '_i', '_]', '_+=', '_a', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_X', '_=', '_max', '_(', '_X', '_,', '_a', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_Y', '_=', '_max', '_(', '_b', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_b', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_b', '_[', '_i', '_]', '_+=', '_b', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_Y', '_=', '_max', '_(', '_Y', '_,', '_b', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_return', '_X', '_+', '_Y', '_NEW', '_', 'LINE', '_DE', 'DENT', '_A', '_=', '_[', '_2', '_,', '_-', '_1', '_,', '_4', '_,', '_-', '_5', '_]', '_NEW', '_', 'LINE', '_B', '_=', '_[', '_4', '_,', '_-', '_3', '_,', '_12', '_,', '_4', '_,', '_-', '_3', '_]', '_NEW', '_', 'LINE', '_print', '_(', '_max', 'Pres', 'um', '_(', '_A', '_,', '_B', '_)', '_)', '_NEW', '_', 'LINE', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   source_ids: 1 536 943 12236 379 261 279 269 324 262 294 12887 67 5997 30009 1139 273 943 261 279 306 374 308 269 374 262 12887 67 5997 364 277 316 1048 261 404 269 562 261 279 262 262 294 12887 67 5997 30009 279 306 277 308 1011 279 306 277 300 404 308 12887 67 5997 1139 273 943 261 1139 269 279 306 277 308 262 12887 67 5997 2030 18981 1624 273 943 261 324 306 374 308 269 374 262 12887 67 5997 364 277 316 1048 261 404 269 562 261 324 262 262 294 12887 67 5997 30009 324 306 277 308 1011 324 306 277 300 404 308 12887 67 5997 1624 273 943 261 1624 269 324 306 277 308 262 12887 67 5997 2030 18981 327 1139 397 1624 12887 67 5997 2030 18981 432 273 306 576 269 300 404 269 1059 269 300 1381 308 12887 67 5997 605 273 306 1059 269 300 890 269 2593 269 1059 269 300 890 308 12887 67 5997 1172 261 943 12236 379 261 432 269 605 262 262 12887 67 5997 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_tokens: ['<s>', 'Maximum', '_Prefix', '_Sum', '_possible', '_by', '_merging', '_two', '_given', '_arrays', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   target_ids: 1 13528 10139 9352 3323 635 17256 2795 864 5352 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   *** Example ***
03/05/2023 13:27:14 - INFO - __main__ -   idx: 1
03/05/2023 13:27:14 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_lo', '_=', '_1', '_NEW', '_', 'LINE', '_hi', '_=', '_round', '_(', '_math', '_.', '_pow', '_(', '_n', '_,', '_1', '_/', '_3', '_)', '_)', '_NEW', '_', 'LINE', '_while', '_(', '_lo', '_<=', '_hi', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_curr', '_=', '_(', '_lo', '_*', '_lo', '_*', '_lo', '_+', '_hi', '_*', '_hi', '_*', '_hi', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_curr', '_==', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_return', '_True', '_NEW', '_', 'LINE', '_DE', 'DENT', '_if', '_(', '_curr', '_<', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_lo', '_+=', '_1', '_NEW', '_', 'LINE', '_DE', 'DENT', '_else', '_:', '_NEW', '_', 'LINE', '_INDENT', '_hi', '_-=', '_1', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_return', '_False', '_NEW', '_', 'LINE', '_DE', 'DENT', '_N', '_=', '_28', '_NEW', '_', 'LINE', '_if', '_(', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_N', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_print', '_(', '_"', '_True', '_"', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_else', '_:', '_NEW', '_', 'LINE', '_INDENT', '_print', '_(', '_"', '_False', '_"', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   source_ids: 1 5666 4233 12887 67 5997 1652 2142 951 11710 39 23317 261 290 262 294 12887 67 5997 30009 437 273 404 12887 67 5997 10118 273 3643 261 4233 263 7602 261 290 269 404 342 890 262 262 12887 67 5997 1323 261 437 1648 10118 262 294 12887 67 5997 30009 4306 273 261 437 380 437 380 437 397 10118 380 10118 380 10118 262 12887 67 5997 309 261 4306 422 290 262 294 12887 67 5997 30009 327 1053 12887 67 5997 2030 18981 309 261 4306 411 290 262 294 12887 67 5997 30009 437 1011 404 12887 67 5997 2030 18981 469 294 12887 67 5997 30009 10118 3947 404 12887 67 5997 2030 18981 2030 18981 327 1083 12887 67 5997 2030 18981 423 273 9131 12887 67 5997 309 261 2142 951 11710 39 23317 261 423 262 262 294 12887 67 5997 30009 1172 261 315 1053 315 262 12887 67 5997 2030 18981 469 294 12887 67 5997 30009 1172 261 315 1083 315 262 12887 67 5997 2030 18981 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_tokens: ['<s>', 'Check', '_if', '_a', '_number', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_positive', '_perfect', '_c', 'ubes', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   target_ids: 1 1564 309 279 1300 848 506 10584 487 2142 434 2795 6895 24746 276 23317 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   *** Example ***
03/05/2023 13:27:14 - INFO - __main__ -   idx: 2
03/05/2023 13:27:14 - INFO - __main__ -   source_tokens: ['<s>', 's', 'ieve', '_=', '_[', '_1', '_]', '_*', '_(', '_1000000', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_def', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_N', '_=', '_1000000', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_N', '_+', '_1', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_if', '_i', '_*', '_i', '_>', '_N', '_:', '_NEW', '_', 'LINE', '_INDENT', '_break', '_NEW', '_', 'LINE', '_DE', 'DENT', '_if', '_(', '_s', 'ieve', '_[', '_i', '_]', '_==', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_continue', '_NEW', '_', 'LINE', '_DE', 'DENT', '_for', '_j', '_in', '_range', '_(', '_i', '_*', '_i', '_,', '_N', '_+', '_1', '_,', '_i', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_s', 'ieve', '_[', '_j', '_]', '_=', '_0', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_DE', 'DENT', '_def', '_getArray', '_(', '_arr', '_,', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_A', '_=', '_[', '_0', '_]', '_*', '_N', '_NEW', '_', 'LINE', '_v', '_=', '_[', '_]', '_NEW', '_', 'LINE', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_int', '_(', '_1', 'e', '5', '_)', '_+', '_1', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_if', '_(', '_s', 'ieve', '_[', '_i', '_]', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_v', '_.', '_append', '_(', '_i', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_j', '_=', '_0', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_ind', '_=', '_arr', '_[', '_i', '_]', '_NEW', '_', 'LINE', '_if', '_(', '_A', '_[', '_i', '_]', '_!=', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_continue', '_NEW', '_', 'LINE', '_DE', 'DENT', '_elif', '_(', '_A', '_[', '_ind', '_]', '_!=', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_A', '_[', '_i', '_]', '_=', '_A', '_[', '_ind', '_]', '_NEW', '_', 'LINE', '_DE', 'DENT', '_else', '_:', '_NEW', '_', 'LINE', '_INDENT', '_prime', '_=', '_v', '_[', '_j', '_]', '_NEW', '_', 'LINE', '_A', '_[', '_i', '_]', '_=', '_prime', '_NEW', '_', 'LINE', '_A', '_[', '_ind', '_]', '_=', '_A', '_[', '_i', '_]', '_NEW', '_', 'LINE', '_j', '_+=', '_1', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_for', '_i', '_in', '_range', '_(', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_print', '_(', '_A', '_[', '_i', '_]', '_,', '_end', '_=', '_"', '_', 'â', 'ĸ', 'ģ', '_"', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_if', '___', 'name', '__', '_==', "_'", '__', '__', '_main', '__', '__', "_'", '_:', '_NEW', '_', 'LINE', '_INDENT', '_arr', '_=', '_[', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   source_ids: 1 87 21271 273 306 404 308 380 261 15088 397 404 262 12887 67 5997 1652 272 21271 951 2050 4485 261 262 294 12887 67 5997 30009 2552 272 21271 12887 67 5997 423 273 15088 12887 67 5997 364 277 316 1048 261 576 269 423 397 404 262 294 12887 67 5997 30009 309 277 380 277 405 423 294 12887 67 5997 30009 898 12887 67 5997 2030 18981 309 261 272 21271 306 277 308 422 374 262 294 12887 67 5997 30009 1324 12887 67 5997 2030 18981 364 525 316 1048 261 277 380 277 269 423 397 404 269 277 262 294 12887 67 5997 30009 272 21271 306 525 308 273 374 12887 67 5997 2030 18981 2030 18981 2030 18981 1652 12634 261 2454 269 423 262 294 12887 67 5997 30009 2552 272 21271 12887 67 5997 432 273 306 374 308 380 423 12887 67 5997 331 273 306 308 12887 67 5997 272 21271 951 2050 4485 261 262 12887 67 5997 364 277 316 1048 261 576 269 509 261 404 73 25 262 397 404 262 294 12887 67 5997 30009 309 261 272 21271 306 277 308 262 294 12887 67 5997 30009 331 263 714 261 277 262 12887 67 5997 2030 18981 2030 18981 525 273 374 12887 67 5997 364 277 316 1048 261 423 262 294 12887 67 5997 30009 1547 273 2454 306 277 308 12887 67 5997 309 261 432 306 277 308 480 374 262 294 12887 67 5997 30009 1324 12887 67 5997 2030 18981 1327 261 432 306 1547 308 480 374 262 294 12887 67 5997 30009 432 306 277 308 273 432 306 1547 308 12887 67 5997 2030 18981 469 294 12887 67 5997 30009 17014 273 331 306 525 308 12887 67 5997 432 306 277 308 273 17014 12887 67 5997 432 306 1547 308 273 432 306 277 308 12887 67 5997 525 1011 404 12887 67 5997 2030 18981 2030 18981 364 277 316 1048 261 423 262 294 12887 67 5997 30009 1172 261 432 306 277 308 269 679 273 315 225 163 249 228 315 262 12887 67 5997 2030 18981 2030 18981 309 1001 529 972 422 296 389 389 2774 389 389 296 294 12887 67 5997 30009 2454 273 306 2
03/05/2023 13:27:14 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/05/2023 13:27:14 - INFO - __main__ -   target_tokens: ['<s>', 'Generate', '_an', '_N', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   target_ids: 1 4625 392 423 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   *** Example ***
03/05/2023 13:27:14 - INFO - __main__ -   idx: 3
03/05/2023 13:27:14 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_result', '_=', '_0', '_NEW', '_', 'LINE', '_p', '_=', '_1', '_NEW', '_', 'LINE', '_while', '_(', '_N', '_>', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_result', '_+=', '_(', '_p', '_*', '_(', '_N', '_%', '_9', '_)', '_)', '_NEW', '_', 'LINE', '_N', '_=', '_N', '_//', '_9', '_NEW', '_', 'LINE', '_p', '_=', '_p', '_*', '_10', '_NEW', '_', 'LINE', '_DE', 'DENT', '_return', '_result', '_NEW', '_', 'LINE', '_DE', 'DENT', '_if', '___', 'name', '__', '_==', "_'", '__', '__', '_main', '__', '__', "_'", '_:', '_NEW', '_', 'LINE', '_INDENT', '_N', '_=', '_9', '_NEW', '_', 'LINE', '_print', '_(', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   source_ids: 1 536 1104 50 451 1854 261 423 262 294 12887 67 5997 30009 563 273 374 12887 67 5997 293 273 404 12887 67 5997 1323 261 423 405 374 262 294 12887 67 5997 30009 563 1011 261 293 380 261 423 738 2468 262 262 12887 67 5997 423 273 423 368 2468 12887 67 5997 293 273 293 380 1728 12887 67 5997 2030 18981 327 563 12887 67 5997 2030 18981 309 1001 529 972 422 296 389 389 2774 389 389 296 294 12887 67 5997 30009 423 273 2468 12887 67 5997 1172 261 1104 50 451 1854 261 423 262 262 12887 67 5997 2030 18981 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_tokens: ['<s>', 'N', 'th', '_natural', '_number', '_after', '_removing', '_all', '_numbers', '_consisting', '_of', '_the', '_digit', '_9', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   target_ids: 1 50 451 15145 1300 1839 9427 777 5600 23570 434 326 8035 2468 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   *** Example ***
03/05/2023 13:27:14 - INFO - __main__ -   idx: 4
03/05/2023 13:27:14 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_check', '_(', '_A', '_,', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_return', '_1', '_NEW', '_', 'LINE', '_DE', 'DENT', '_dig', '1', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_A', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_dig', '2', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_B', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_dig', '1', '_!=', '_dig', '2', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_return', '_0', '_NEW', '_', 'LINE', '_DE', 'DENT', '_temp', '_=', '_A', '_NEW', '_', 'LINE', '_while', '_(', '_True', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_power', '_=', '_pow', '_(', '_10', '_,', '_dig', '1', '_-', '_1', '_)', '_NEW', '_', 'LINE', '_first', 'digit', '_=', '_A', '_//', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_-', '_first', 'digit', '_*', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_*', '_10', '_+', '_first', 'digit', '_NEW', '_', 'LINE', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_return', '_1', '_NEW', '_', 'LINE', '_DE', 'DENT', '_if', '_(', '_A', '_==', '_temp', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_return', '_0', '_NEW', '_', 'LINE', '_DE', 'DENT', '_DE', 'DENT', '_DE', 'DENT', '_A', '_,', '_B', '_=', '_9', '67', '_,', '_6', '79', '_NEW', '_', 'LINE', '_if', '_(', '_check', '_(', '_A', '_,', '_B', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_INDENT', '_print', '_(', '_"', '_Yes', '_"', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '_else', '_:', '_NEW', '_', 'LINE', '_INDENT', '_print', '_(', '_"', '_No', '_"', '_)', '_NEW', '_', 'LINE', '_DE', 'DENT', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   source_ids: 1 5666 4233 12887 67 5997 1652 866 261 432 269 605 262 294 12887 67 5997 30009 309 261 432 422 605 262 294 12887 67 5997 30009 327 404 12887 67 5997 2030 18981 3097 21 273 4233 263 6346 261 4233 263 613 2163 261 432 262 397 404 262 12887 67 5997 3097 22 273 4233 263 6346 261 4233 263 613 2163 261 605 262 397 404 262 12887 67 5997 309 261 3097 21 480 3097 22 262 294 12887 67 5997 30009 327 374 12887 67 5997 2030 18981 1906 273 432 12887 67 5997 1323 261 1053 262 294 12887 67 5997 30009 7212 273 7602 261 1728 269 3097 21 300 404 262 12887 67 5997 1122 11052 273 432 368 7212 12887 67 5997 432 273 432 300 1122 11052 380 7212 12887 67 5997 432 273 432 380 1728 397 1122 11052 12887 67 5997 309 261 432 422 605 262 294 12887 67 5997 30009 327 404 12887 67 5997 2030 18981 309 261 432 422 1906 262 294 12887 67 5997 30009 327 374 12887 67 5997 2030 18981 2030 18981 2030 18981 432 269 605 273 2468 9599 269 1666 7235 12887 67 5997 309 261 866 261 432 269 605 262 262 294 12887 67 5997 30009 1172 261 315 19925 315 262 12887 67 5997 2030 18981 469 294 12887 67 5997 30009 1172 261 315 2631 315 262 12887 67 5997 2030 18981 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_tokens: ['<s>', 'Check', '_if', '_an', '_integer', '_is', '_rotation', '_of', '_another', '_given', '_integer', '</s>']
03/05/2023 13:27:14 - INFO - __main__ -   target_ids: 1 1564 309 392 3571 353 6752 434 4042 864 3571 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/05/2023 13:27:14 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
/home/ysnamgoong42/miniconda3/envs/xlcost/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/05/2023 13:27:27 - INFO - __main__ -   ***** Running training *****
03/05/2023 13:27:27 - INFO - __main__ -     Num examples = 9263
03/05/2023 13:27:27 - INFO - __main__ -     Batch size = 16
03/05/2023 13:27:27 - INFO - __main__ -     Num epoch = 9
03/05/2023 13:28:11 - INFO - __main__ -     step 100 loss 0.4954
03/05/2023 13:28:54 - INFO - __main__ -     step 200 loss 0.4419
03/05/2023 13:29:38 - INFO - __main__ -     step 300 loss 0.4173
03/05/2023 13:30:21 - INFO - __main__ -     step 400 loss 0.4013
03/05/2023 13:31:05 - INFO - __main__ -     step 500 loss 0.3905
03/05/2023 13:31:48 - INFO - __main__ -     step 600 loss 0.3805
03/05/2023 13:32:32 - INFO - __main__ -     step 700 loss 0.3695
03/05/2023 13:33:15 - INFO - __main__ -     step 800 loss 0.3607
03/05/2023 13:33:59 - INFO - __main__ -     step 900 loss 0.3533
03/05/2023 13:34:42 - INFO - __main__ -     step 1000 loss 0.3469
03/05/2023 13:35:26 - INFO - __main__ -     step 1100 loss 0.3416
03/05/2023 13:35:51 - INFO - __main__ -   
***** Running evaluation *****
03/05/2023 13:35:51 - INFO - __main__ -     Num examples = 472
03/05/2023 13:35:51 - INFO - __main__ -     Batch size = 16
03/05/2023 13:35:55 - INFO - __main__ -     eval_ppl = 1.3367
03/05/2023 13:35:55 - INFO - __main__ -     global_step = 1157
03/05/2023 13:35:55 - INFO - __main__ -     train_loss = 0.3381
03/05/2023 13:35:55 - INFO - __main__ -     ********************
03/05/2023 13:35:57 - INFO - __main__ -     Best ppl:1.3367
03/05/2023 13:35:57 - INFO - __main__ -     ********************
03/05/2023 13:37:21 - INFO - __main__ -     bleu-4 = 9.82 
03/05/2023 13:37:21 - INFO - __main__ -     xMatch = 1.6949 
03/05/2023 13:37:21 - INFO - __main__ -     ********************
03/05/2023 13:37:21 - INFO - __main__ -     Best bleu:9.82
03/05/2023 13:37:21 - INFO - __main__ -     ********************
03/05/2023 13:37:42 - INFO - __main__ -     step 1200 loss 0.2805
03/05/2023 13:38:25 - INFO - __main__ -     step 1300 loss 0.2627
03/05/2023 13:39:08 - INFO - __main__ -     step 1400 loss 0.2598
03/05/2023 13:39:52 - INFO - __main__ -     step 1500 loss 0.2567
03/05/2023 13:40:35 - INFO - __main__ -     step 1600 loss 0.2548
03/05/2023 13:41:18 - INFO - __main__ -     step 1700 loss 0.2538
03/05/2023 13:42:02 - INFO - __main__ -     step 1800 loss 0.2507
03/05/2023 13:42:45 - INFO - __main__ -     step 1900 loss 0.2466
03/05/2023 13:43:29 - INFO - __main__ -     step 2000 loss 0.2437
03/05/2023 13:44:12 - INFO - __main__ -     step 2100 loss 0.2407
03/05/2023 13:44:56 - INFO - __main__ -     step 2200 loss 0.2387
03/05/2023 13:45:39 - INFO - __main__ -     step 2300 loss 0.2366
03/05/2023 13:45:45 - INFO - __main__ -   
***** Running evaluation *****
03/05/2023 13:45:45 - INFO - __main__ -     Num examples = 472
03/05/2023 13:45:45 - INFO - __main__ -     Batch size = 16
03/05/2023 13:45:49 - INFO - __main__ -     eval_ppl = 1.34157
03/05/2023 13:45:49 - INFO - __main__ -     global_step = 2314
03/05/2023 13:45:49 - INFO - __main__ -     train_loss = 0.2361
03/05/2023 13:45:49 - INFO - __main__ -     ********************
03/05/2023 13:47:33 - INFO - __main__ -     bleu-4 = 9.04 
03/05/2023 13:47:33 - INFO - __main__ -     xMatch = 2.5424 
03/05/2023 13:47:33 - INFO - __main__ -     ********************
03/05/2023 13:48:10 - INFO - __main__ -     step 2400 loss 0.2026
03/05/2023 13:48:53 - INFO - __main__ -     step 2500 loss 0.199
03/05/2023 13:49:36 - INFO - __main__ -     step 2600 loss 0.1987
03/05/2023 13:50:20 - INFO - __main__ -     step 2700 loss 0.1965
03/05/2023 13:51:03 - INFO - __main__ -     step 2800 loss 0.1959
03/05/2023 13:51:47 - INFO - __main__ -     step 2900 loss 0.1943
03/05/2023 13:52:30 - INFO - __main__ -     step 3000 loss 0.1917
03/05/2023 13:53:14 - INFO - __main__ -     step 3100 loss 0.189
03/05/2023 13:53:57 - INFO - __main__ -     step 3200 loss 0.187
03/05/2023 13:54:41 - INFO - __main__ -     step 3300 loss 0.1851
03/05/2023 13:55:24 - INFO - __main__ -     step 3400 loss 0.1839
03/05/2023 13:55:55 - INFO - __main__ -   
***** Running evaluation *****
03/05/2023 13:55:55 - INFO - __main__ -     Num examples = 472
03/05/2023 13:55:55 - INFO - __main__ -     Batch size = 16
03/05/2023 13:55:59 - INFO - __main__ -     eval_ppl = 1.3576
03/05/2023 13:55:59 - INFO - __main__ -     global_step = 3471
03/05/2023 13:55:59 - INFO - __main__ -     train_loss = 0.1829
03/05/2023 13:55:59 - INFO - __main__ -     ********************
03/05/2023 13:57:35 - INFO - __main__ -     bleu-4 = 9.23 
03/05/2023 13:57:35 - INFO - __main__ -     xMatch = 1.4831 
03/05/2023 13:57:35 - INFO - __main__ -     ********************
03/05/2023 13:57:48 - INFO - __main__ -     step 3500 loss 0.1723
03/05/2023 13:58:31 - INFO - __main__ -     step 3600 loss 0.1579
03/05/2023 13:59:15 - INFO - __main__ -     step 3700 loss 0.1561
03/05/2023 13:59:58 - INFO - __main__ -     step 3800 loss 0.1555
03/05/2023 14:00:41 - INFO - __main__ -     step 3900 loss 0.1551
03/05/2023 14:01:25 - INFO - __main__ -     step 4000 loss 0.1552
03/05/2023 14:02:08 - INFO - __main__ -     step 4100 loss 0.1542
03/05/2023 14:02:52 - INFO - __main__ -     step 4200 loss 0.152
03/05/2023 14:03:35 - INFO - __main__ -     step 4300 loss 0.1507
03/05/2023 14:04:19 - INFO - __main__ -     step 4400 loss 0.1494
03/05/2023 14:05:02 - INFO - __main__ -     step 4500 loss 0.1486
03/05/2023 14:05:46 - INFO - __main__ -     step 4600 loss 0.1481
03/05/2023 14:05:58 - INFO - __main__ -   
***** Running evaluation *****
03/05/2023 14:05:58 - INFO - __main__ -     Num examples = 472
03/05/2023 14:05:58 - INFO - __main__ -     Batch size = 16
03/05/2023 14:06:02 - INFO - __main__ -     eval_ppl = 1.36905
03/05/2023 14:06:02 - INFO - __main__ -     global_step = 4628
03/05/2023 14:06:02 - INFO - __main__ -     train_loss = 0.1477
03/05/2023 14:06:02 - INFO - __main__ -     ********************
03/05/2023 14:07:42 - INFO - __main__ -     bleu-4 = 8.93 
03/05/2023 14:07:42 - INFO - __main__ -     xMatch = 1.4831 
03/05/2023 14:07:42 - INFO - __main__ -     ********************
03/05/2023 14:08:14 - INFO - __main__ -     step 4700 loss 0.1335
03/05/2023 14:08:57 - INFO - __main__ -     step 4800 loss 0.1306
03/05/2023 14:09:41 - INFO - __main__ -     step 4900 loss 0.1301
03/05/2023 14:10:24 - INFO - __main__ -     step 5000 loss 0.1294
03/05/2023 14:11:08 - INFO - __main__ -     step 5100 loss 0.1302
03/05/2023 14:11:51 - INFO - __main__ -     step 5200 loss 0.1306
03/05/2023 14:12:35 - INFO - __main__ -     step 5300 loss 0.1296
03/05/2023 14:13:18 - INFO - __main__ -     step 5400 loss 0.1285
03/05/2023 14:14:02 - INFO - __main__ -     step 5500 loss 0.1282
03/05/2023 14:14:45 - INFO - __main__ -     step 5600 loss 0.1275
03/05/2023 14:15:29 - INFO - __main__ -     step 5700 loss 0.1275
03/05/2023 14:16:06 - INFO - __main__ -   
***** Running evaluation *****
03/05/2023 14:16:06 - INFO - __main__ -     Num examples = 472
03/05/2023 14:16:06 - INFO - __main__ -     Batch size = 16
03/05/2023 14:16:10 - INFO - __main__ -     eval_ppl = 1.37787
03/05/2023 14:16:10 - INFO - __main__ -     global_step = 5785
03/05/2023 14:16:10 - INFO - __main__ -     train_loss = 0.1274
03/05/2023 14:16:10 - INFO - __main__ -     ********************
03/05/2023 14:17:56 - INFO - __main__ -     bleu-4 = 8.87 
03/05/2023 14:17:56 - INFO - __main__ -     xMatch = 1.4831 
03/05/2023 14:17:56 - INFO - __main__ -     ********************
T5ForConditionalGeneration :  /home/ysnamgoong42/miniconda3/envs/xlcost/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py
03/05/2023 14:18:01 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='Salesforce/codet5-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=16, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/ysnamgoong42/ws/XLCoST/codet5_pl_nl_program/Python-desc/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=400, max_steps=-1, max_target_length=100, model_name_or_path='Salesforce/codet5-base', model_type='codet5', no_cuda=False, num_train_epochs=3.0, output_dir='/home/ysnamgoong42/ws/XLCoST/codet5_pl_nl_program/Python-desc', seed=42, test_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/test-Python-desc-tok.py,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/test-Python-desc-tok.txt', tokenizer_name='Salesforce/codet5-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
03/05/2023 14:18:01 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/05/2023 14:18:09 - INFO - __main__ -   reload model from /home/ysnamgoong42/ws/XLCoST/codet5_pl_nl_program/Python-desc/checkpoint-best-ppl/pytorch_model.bin
03/05/2023 14:18:11 - INFO - __main__ -   Test file: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/test-Python-desc-tok.py,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc/Python-desc/test-Python-desc-tok.txt
T5ForConditionalGeneration :  /home/ysnamgoong42/miniconda3/envs/xlcost/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py
  0%|          | 0/56 [00:00<?, ?it/s]  2%|▏         | 1/56 [00:01<01:38,  1.79s/it]  4%|▎         | 2/56 [00:03<01:33,  1.74s/it]  5%|▌         | 3/56 [00:04<01:25,  1.61s/it]  7%|▋         | 4/56 [00:06<01:27,  1.69s/it]  9%|▉         | 5/56 [00:08<01:22,  1.62s/it] 11%|█         | 6/56 [00:10<01:37,  1.96s/it] 12%|█▎        | 7/56 [00:12<01:31,  1.87s/it] 14%|█▍        | 8/56 [00:14<01:30,  1.88s/it] 16%|█▌        | 9/56 [00:16<01:29,  1.91s/it] 18%|█▊        | 10/56 [00:19<01:44,  2.28s/it] 20%|█▉        | 11/56 [00:21<01:42,  2.29s/it] 21%|██▏       | 12/56 [00:24<01:49,  2.48s/it] 23%|██▎       | 13/56 [00:27<01:47,  2.50s/it] 25%|██▌       | 14/56 [00:29<01:47,  2.55s/it] 27%|██▋       | 15/56 [00:32<01:48,  2.64s/it] 29%|██▊       | 16/56 [00:35<01:50,  2.76s/it] 30%|███       | 17/56 [00:38<01:50,  2.84s/it] 32%|███▏      | 18/56 [00:41<01:49,  2.89s/it] 34%|███▍      | 19/56 [00:44<01:49,  2.95s/it] 36%|███▌      | 20/56 [00:48<01:54,  3.17s/it] 38%|███▊      | 21/56 [00:52<01:53,  3.25s/it] 39%|███▉      | 22/56 [00:55<01:52,  3.32s/it] 41%|████      | 23/56 [00:59<01:52,  3.40s/it] 43%|████▎     | 24/56 [01:03<01:55,  3.60s/it] 45%|████▍     | 25/56 [01:06<01:53,  3.65s/it] 46%|████▋     | 26/56 [01:11<01:55,  3.83s/it] 48%|████▊     | 27/56 [01:15<01:56,  4.01s/it] 50%|█████     | 28/56 [01:20<01:58,  4.24s/it] 52%|█████▏    | 29/56 [01:26<02:08,  4.77s/it] 54%|█████▎    | 30/56 [01:31<02:02,  4.71s/it] 55%|█████▌    | 31/56 [01:35<01:57,  4.70s/it] 57%|█████▋    | 32/56 [01:41<01:58,  4.94s/it] 59%|█████▉    | 33/56 [01:46<01:56,  5.06s/it] 61%|██████    | 34/56 [01:53<02:03,  5.60s/it] 62%|██████▎   | 35/56 [01:58<01:56,  5.56s/it] 64%|██████▍   | 36/56 [02:04<01:51,  5.55s/it] 66%|██████▌   | 37/56 [02:09<01:45,  5.56s/it] 68%|██████▊   | 38/56 [02:15<01:40,  5.61s/it] 70%|██████▉   | 39/56 [02:22<01:39,  5.83s/it] 71%|███████▏  | 40/56 [02:28<01:36,  6.03s/it] 73%|███████▎  | 41/56 [02:34<01:31,  6.13s/it] 75%|███████▌  | 42/56 [02:41<01:27,  6.25s/it] 77%|███████▋  | 43/56 [02:48<01:22,  6.36s/it] 79%|███████▊  | 44/56 [02:54<01:16,  6.38s/it] 80%|████████  | 45/56 [03:01<01:11,  6.54s/it] 82%|████████▏ | 46/56 [03:09<01:09,  6.92s/it] 84%|████████▍ | 47/56 [03:16<01:03,  7.07s/it] 86%|████████▌ | 48/56 [03:23<00:56,  7.06s/it] 88%|████████▊ | 49/56 [03:31<00:50,  7.21s/it] 89%|████████▉ | 50/56 [03:38<00:43,  7.19s/it] 91%|█████████ | 51/56 [03:46<00:36,  7.37s/it] 93%|█████████▎| 52/56 [03:53<00:29,  7.45s/it] 95%|█████████▍| 53/56 [04:01<00:22,  7.51s/it] 96%|█████████▋| 54/56 [04:09<00:15,  7.62s/it] 98%|█████████▊| 55/56 [04:17<00:07,  7.70s/it]100%|██████████| 56/56 [04:24<00:00,  7.68s/it]100%|██████████| 56/56 [04:24<00:00,  4.73s/it]
03/05/2023 14:22:37 - INFO - __main__ -     bleu-4 = 9.77 
03/05/2023 14:22:37 - INFO - __main__ -     xMatch = 1.1274 
03/05/2023 14:22:37 - INFO - __main__ -     ********************
tokenizer.decode(top_preds[0]): Minimize the sum of product of all subarrays of an array
tokenizer.decode(top_preds[0]): Find the number of K
tokenizer.decode(top_preds[0]): Number of ways to split a number into two subarrays such that the sum of digits is equal to the sum of their digits
tokenizer.decode(top_preds[0]): Maximum time with difference in range [ L , R ]
tokenizer.decode(top_preds[0]): Maximum point of intersection of two points
tokenizer.decode(top_preds[0]): Check if a number is undulating or not
tokenizer.decode(top_preds[0]): Set the bit number in the binary representation of a number
tokenizer.decode(top_preds[0]): Left rotation of an array by one
tokenizer.decode(top_preds[0]): Find the smallest missing element in an array
tokenizer.decode(top_preds[0]): Longest Common Subsequence | DP
tokenizer.decode(top_preds[0]): Count number of ways to reach the top left corner
tokenizer.decode(top_preds[0]): Miiller Prime Numbers
tokenizer.decode(top_preds[0]): Count number of triplets ( a , b ) such that ( a ^ b ) = 0
tokenizer.decode(top_preds[0]): Program to find the Area of a Sector
tokenizer.decode(top_preds[0]): Number of ways to split N numbers into two subarrays such that their sum is equal to their index
tokenizer.decode(top_preds[0]): Longest Increasing Subsequence | DP
tokenizer.decode(top_preds[0]): Seires Sum
tokenizer.decode(top_preds[0]): Partition array into two parts sorted in increasing order
tokenizer.decode(top_preds[0]): Maximize the number of squares that can be formed from two given numbers
tokenizer.decode(top_preds[0]): Count number of sets ( i , j ) such that a [ i ] [ j ] = a [ i ] [ j ] and a [ j ] [ i ] = a [ j ] [ i ]
tokenizer.decode(top_preds[0]): Number of paths from top left to bottom right in a matrix
tokenizer.decode(top_preds[0]): Add two numbers without using Bitwise AND and Bitwise XOR
tokenizer.decode(top_preds[0]): Queries to find the Bitwise XOR of all prefixes of an array
tokenizer.decode(top_preds[0]): Reverse an array in O ( n ) time and O ( 1 ) extra space in O ( 1 ) extra space
tokenizer.decode(top_preds[0]): Maximize count of abca , BOOK and BAND strings from a given string
tokenizer.decode(top_preds[0]): Longest subsequence having different elements in the given array
tokenizer.decode(top_preds[0]): Count of subsets with sum less than K
tokenizer.decode(top_preds[0]): Count pairs from an array whose product is greater than K * arr [ j ]
tokenizer.decode(top_preds[0]): Check if it is possible to make two sorted arrays sorted
tokenizer.decode(top_preds[0]): Minimize the number of subgroups required to reach the end of an array
tokenizer.decode(top_preds[0]): Find the number of shifts required to make all array elements equal
tokenizer.decode(top_preds[0]): Minimize the number of operations required to convert a Binary String to a Binary String
tokenizer.decode(top_preds[0]): Check if all elements of an array have equal sum
tokenizer.decode(top_preds[0]): Maximum Sum Contiguous Subarray | DP
tokenizer.decode(top_preds[0]): Generate palindromic strings from given string
tokenizer.decode(top_preds[0]): Encrypt a string using given algorithm
tokenizer.decode(top_preds[0]): Count occurrences of a word in a string
tokenizer.decode(top_preds[0]): Area of the circle that can be inscribed in an equilateral triangle
tokenizer.decode(top_preds[0]): Minimize the number of subsets that can be formed from the first N natural numbers
tokenizer.decode(top_preds[0]): Product of all pairs in an array such that their sum is divisible by their product
tokenizer.decode(top_preds[0]): Check if a number can be reduced to a given number
tokenizer.decode(top_preds[0]): Check if a point exists in the given triangle
tokenizer.decode(top_preds[0]): Maximize sum of subarrays of size K
tokenizer.decode(top_preds[0]): Check if a number can be represented as sum of k prime factors
tokenizer.decode(top_preds[0]): Compare two numbers with their logarithmic product
tokenizer.decode(top_preds[0]): Find the balanced array after performing given operations on given array
tokenizer.decode(top_preds[0]): Check if two arrays have equal sum and product equal to their product
tokenizer.decode(top_preds[0]): Average of odd numbers
tokenizer.decode(top_preds[0]): Count pairs with maximum frequency in an array
tokenizer.decode(top_preds[0]): Minimum number of operations required to reduce a number to 0
tokenizer.decode(top_preds[0]): Reverse of digits of a number
tokenizer.decode(top_preds[0]): Check if a string can be formed from a given pattern or not
tokenizer.decode(top_preds[0]): Number of diagonals in convex polygon
tokenizer.decode(top_preds[0]): Print k substrings of a given string
tokenizer.decode(top_preds[0]): Lexicographically smallest element in an array such that their sum is equal to their sum
tokenizer.decode(top_preds[0]): Minimize difference between minimum and maximum of two elements in an array
